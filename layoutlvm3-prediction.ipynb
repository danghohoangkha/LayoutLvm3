{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Looking for C:\\Users\\Admin\\.keras-ocr\\craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Looking for C:\\Users\\Admin\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "import glob\n",
    "from pytesseract import pytesseract\n",
    "from lxml import etree\n",
    "import ast\n",
    "import torch\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "from transformers import LayoutLMv3ForTokenClassification, AutoProcessor, AutoModelForTokenClassification\n",
    "from datasets.features import ClassLabel\n",
    "import keras_ocr\n",
    "\n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained('./test/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = './bill_dataset/train/data-00000-of-00001.arrow'\n",
    "test_file_path = './bill_dataset/test/data-00000-of-00001.arrow'\n",
    "dataset = load_dataset('arrow', data_files={'train': train_file_path, 'test': test_file_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_and_boxes(image):\n",
    "    # Load the image\n",
    "\n",
    "    regconize_image = keras_ocr.tools.read(image)\n",
    "    prediction_groups = pipeline.recognize([regconize_image])\n",
    "\n",
    "    # Initialize lists to hold words and their bounding boxes\n",
    "    words = []\n",
    "    boxes = []\n",
    "\n",
    "    # Iterate over each data point\n",
    "    for text, box in prediction_groups[0]:\n",
    "        x1, y1 = min([coord[0] for coord in box]), min([coord[1] for coord in box])\n",
    "        x2, y2 = max([coord[0] for coord in box]), max([coord[1] for coord in box])\n",
    "        box = (x1, y1, x2, y2)\n",
    "        words.append(text)\n",
    "        boxes.append(box)\n",
    "\n",
    "    return words, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_box(bbox, width, height):\n",
    "     return [\n",
    "         int(width * (bbox[0] / 1000)),\n",
    "         int(height * (bbox[1] / 1000)),\n",
    "         int(width * (bbox[2] / 1000)),\n",
    "         int(height * (bbox[3] / 1000)),\n",
    "     ]\n",
    "\n",
    "def normalize_bbox(bbox, size):\n",
    "    return [\n",
    "        int(1000 * bbox[0] / size[0]),\n",
    "        int(1000 * bbox[1] / size[1]),\n",
    "        int(1000 * bbox[2] / size[0]),\n",
    "        int(1000 * bbox[3] / size[1]),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bounding_box_to_string(box):\n",
    "    bounding_box_str = f\"{box[0]},{box[1]},{box[2]},{box[3]}\"\n",
    "    return bounding_box_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "5/5 [==============================] - 3s 594ms/step\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "words_boxs_dict = {}\n",
    "image_path = './gray_image/noise1.jpg'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "size = image.size\n",
    "words, bboxes = get_words_and_boxes(image_path)\n",
    "\n",
    "for item1, item2 in zip(words, bboxes):\n",
    "    bound_str = convert_bounding_box_to_string(item2)\n",
    "    words_boxs_dict[bound_str] = item1\n",
    "\n",
    "boxes = [normalize_bbox(box, size) for box in bboxes]\n",
    "labels = np.full(len(boxes), 0, dtype=int)\n",
    "encoding = processor(image, words, boxes=boxes, word_labels=labels, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "predictions = logits.argmax(-1).squeeze().tolist()\n",
    "labels = encoding.labels.squeeze().tolist()\n",
    "\n",
    "token_boxes = encoding.bbox.squeeze().tolist()\n",
    "width, height = image.size\n",
    "\n",
    "true_predictions = [model.config.id2label[pred] for pred, label in zip(predictions, labels) if label != - 100]\n",
    "true_labels = [model.config.id2label[label] for prediction, label in zip(predictions, labels) if label != -100]\n",
    "true_boxes = [unnormalize_box(box, width, height) for box, label in zip(token_boxes, labels) if label != -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_box(box):\n",
    "    return words_boxs_dict[box]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_config = './Label_Config.xml'\n",
    "tree = etree.parse(label_config)\n",
    "root = tree.getroot()\n",
    "label2color = {label.get('value'): label.get('background') for label in root.findall(\".//Label\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict(label, text, coordinates, dictionary):\n",
    "    # If the label exists, append the new tuple to the existing list\n",
    "    if label in dictionary:\n",
    "        dictionary[label].append((text, coordinates))\n",
    "    else:\n",
    "        # If the label does not exist, create a new key with a new list\n",
    "        dictionary[label] = [(text, coordinates)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box_1, box_2):\n",
    "    poly_1 = Polygon(box_1)\n",
    "    poly_2 = Polygon(box_2)\n",
    "    # print(poly_1,poly_2)\n",
    "    # iou = poly_1.intersection(poly_2).area / poly_1.union(poly_2).area\n",
    "    iou = poly_1.intersection(poly_2).area\n",
    "    min_area = min(poly_1.area,poly_2.area)\n",
    "    return iou/min_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr_box_overlapse_predict_box(ocr_boxes, predict_box, width, height):\n",
    "    for box in ocr_boxes:\n",
    "        try:\n",
    "            (x1,y1,x2,y2) = box\n",
    "            (x1p,y1p,x2p,y2p) = predict_box\n",
    "            box1 = [[x1, y1], [x2, y1], [x2, y2], [x1, y2]]\n",
    "            box2 = [[x1p, y1p], [x2p, y1p], [x2p, y2p], [x1p, y2p]]\n",
    "            overlap_perc = calculate_iou(box1,box2)\n",
    "            if(overlap_perc > 0.80):\n",
    "                return list(box)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(image)\n",
    "width, height = image.size\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "def iob_to_label(label):\n",
    "    label = label\n",
    "    if not label:\n",
    "      return 'other'\n",
    "    return label\n",
    "\n",
    "mydict = {}\n",
    "\n",
    "for prediction, box in zip(true_predictions, true_boxes):\n",
    "    ocr_boxs = get_ocr_box_overlapse_predict_box(bboxes, box, width, height)\n",
    "    text = ''\n",
    "    if (ocr_boxs != None):\n",
    "      text = words_boxs_dict[convert_bounding_box_to_string(ocr_boxs)]\n",
    "    predicted_label = iob_to_label(prediction).lower()\n",
    "    draw.rectangle(box, outline=label2color[predicted_label])\n",
    "    draw.text((box[0] + 10, box[1] - 10), text=predicted_label, fill=label2color[predicted_label], font=font)\n",
    "    add_to_dict(predicted_label, text, ocr_boxs, mydict)\n",
    "\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('shell', [1459.7988, 58.254883, 1535.1875, 95.94922]), ('uk', [1658.5508, 58.254883, 1709.9521, 95.94922]), ('limited', [1713.3789, 58.254883, 1833.3154, 95.94922]), ('elder', [1836.7422, 58.254883, 1918.9844, 95.94922]), ('586512', [2038.9209, 58.254883, 2179.418, 95.94922]), ('elder', [2186.2715, 58.254883, 2271.9404, 95.94922]), ('gater', [2265.7197, 54.61725, 2368.5225, 103.17178]), ('energy', [1540.0719, 60.602505, 1653.0698, 104.932625]), ('houses', [1924.1887, 60.314358, 2033.7509, 100.059616]), ('mka', [2220.539, 99.37598, 2299.3545, 137.07031]), ('milton', [1984.0928, 102.802734, 2083.4688, 137.07031]), ('keynes', [2087.8599, 100.93954, 2212.645, 150.16718]), ('ilrs', [2306.208, 102.802734, 2364.463, 137.07031])]\n"
     ]
    }
   ],
   "source": [
    "print(mydict['company_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_info = mydict['company_info']\n",
    "site_address = mydict['site_address']\n",
    "paragraph = ' '.join(text for text, _ in company_info if text!='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Line Height: 39.55792764516977\n"
     ]
    }
   ],
   "source": [
    "box_heights = [box[3] - box[1] for _, box in company_info]\n",
    "average_line_height = sum(box_heights) / len(box_heights) if box_heights else 0\n",
    "print(f\"Average Line Height: {average_line_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_number(y_coord):\n",
    "    return int(y_coord / average_line_height)\n",
    "\n",
    "# Sort by Y-coordinate, and then by X-coordinate within each line\n",
    "sorted_data = sorted(site_address, key=lambda x: (get_line_number(x[1][1]), x[1][0]))\n",
    "\n",
    "# Concatenate the text to form a paragraph\n",
    "paragraph = ' '.join(text for text, _ in sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'barking first floor flat 740 road london greater london e13 9lb'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
